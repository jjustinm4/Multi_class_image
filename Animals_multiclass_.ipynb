{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Animals-multiclass .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7AEQdzlkeWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbxAdJX6ysIJ",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing the Training set                 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6VTgNZByu22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,                                                                  \n",
        "\n",
        "                                   shear_range = 0.2, \n",
        "\n",
        "                                   zoom_range = 0.2, \n",
        "\n",
        "                                   horizontal_flip = True) \n",
        "\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set', \n",
        "\n",
        "                                                 target_size = (64, 64), \n",
        "\n",
        "                                                 batch_size = 32, \n",
        "\n",
        "                                                 class_mode = 'binary') \n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AS3StzSyxLc",
        "colab_type": "text"
      },
      "source": [
        "rotation_range is a value in degrees (0-180), a range within which to randomly rotate pictures \n",
        "\n",
        "width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally \n",
        "\n",
        "rescale is a value by which we will multiply the data before any other processing. Our original images consist in RGB coefficients in the 0-25 \n",
        "\n",
        "        5, but such values would be too high for our models to process (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor. \n",
        "\n",
        "shear_range is for randomly applying shearing transformations \n",
        "\n",
        "zoom_range is for randomly zooming inside pictures \n",
        "\n",
        "horizontal_flip is for randomly flipping half of the images horizontally --relevant when there are no assumptions of horizontal assymetry (e.g. real-world pictures). \n",
        "\n",
        "fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift. \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IzBOy1Ey3Do",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing the Test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZnKSoHhy5OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)   test data gen is an object of imagedatagenerator classs we pre defined  \n",
        "\n",
        "                                                       \n",
        "\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',      \n",
        "\n",
        "                                            target_size = (64, 64), \n",
        "\n",
        "                                            batch_size = 32, \n",
        "\n",
        "                                            class_mode = 'binary') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ6PLhisy7jN",
        "colab_type": "text"
      },
      "source": [
        "in this code we are connecting testdatagen to out test set. Low from directory is a function from imagedatagenerator class to add directory  \n",
        "\n",
        "where test data remains.the target size argument is the size of image we fed.batc isze the number of input images we  feed 32 s a classic value  \n",
        "\n",
        "Class mode=binary means we have binary oytcomes this is 1D , in categotrical it returns 2D one hot encoded arrays \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncBxEri4zACP",
        "colab_type": "text"
      },
      "source": [
        "Initialising the CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP-2xbbxzC9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = tf.keras.models.Sequential() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4cZ5DYUzHPm",
        "colab_type": "text"
      },
      "source": [
        "Step 1 - Convolution "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcRMg95rzKjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3])) \n",
        "\n",
        "#Filters means number of feature detector \n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o--8v2KzSoP",
        "colab_type": "text"
      },
      "source": [
        "Step 2 - Pooling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tcfzS97zVHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) \n",
        "\n",
        "#Pool size means the size(x*x) of pool filter added over feature map. Strides means  the number of pixels we are shifting  \n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km7eA2yqz7iV",
        "colab_type": "text"
      },
      "source": [
        "Adding a second convolutional layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPJ8E5qsz8be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) \n",
        "\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) \n",
        "\n",
        " \n",
        "\n",
        "#As in the first layer we don’t need to specifuy the inut size here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hgolZHr0Bdm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqd6Y6-L0FDS",
        "colab_type": "text"
      },
      "source": [
        "Step 3 - Flattening "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd7-qAas0HWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Before flattening all the convolutional layers are reday now we need to flatten them as a 1D array  \n",
        "\n",
        " cnn.add(tf.keras.layers.Flatten()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy-Msko0J-d",
        "colab_type": "text"
      },
      "source": [
        "Step 4 - Full Connection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CbM_ZFO0L4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a fully connected layer with 128 output neurons \n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCKF-rE0TIF",
        "colab_type": "text"
      },
      "source": [
        "Step 5 - Output Layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3n6HxaJ0V32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) \n",
        "#Activation function is sigmoid because it’s a binary classifiaction problem . Softmax shoild  have been used if it was a multi class problem  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SaoeEnp0bU6",
        "colab_type": "text"
      },
      "source": [
        "Part 3 - Training the CNN \n",
        "Compiling the CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGD7EmZv0dSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAnZKerA0fgi",
        "colab_type": "text"
      },
      "source": [
        "Training the CNN on the Training set and evaluating it on the Test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FYJytJp0h8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25) \n",
        "#Training and test sets are already defined "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgsUrSNd0lcT",
        "colab_type": "text"
      },
      "source": [
        "Part 4 - Making a single prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d9IiVmA0oC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import numpy as np \n",
        "\n",
        "from keras.preprocessing import image     ----------- #function for loading single images  \n",
        "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64)) ---#specifying the location and size params \n",
        "test_image = image.img_to_array(test_image)  ---- #test image is a jpg now and this library function converts it into a numpy array  \n",
        "test_image = np.expand_dims(test_image, axis = 0)-- #the batch argument is necesssary but for single images it isnt possible hence add an eextra dimension \n",
        "#using expand_dims function , axis=0 menas the axis to which we are including the dimension and its 0 \n",
        "result = cnn.predict(test_image)     ---this cnn is our previously built model  \n",
        "training_set.class_indices       ---------prints the indices of our test classes as dogs=1 , cats=0 \n",
        "if result[0][0] == 1:             ------------------the result vectior is by default 2D hence 2D indexing needed  \n",
        "  prediction = 'dog' \n",
        "else: \n",
        "  prediction = 'cat' "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}